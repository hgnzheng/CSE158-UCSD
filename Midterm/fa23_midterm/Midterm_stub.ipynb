{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fadc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import random\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcdcf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a8d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a6d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = gzip.open(\"train.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2ef14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for l in z:\n",
    "    d = eval(l)\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a06fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93e80cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37e48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, ypred):\n",
    "    # Compute the square of each term.\n",
    "    ds = [(a-b)**2 for (a,b) in zip(y, ypred)]\n",
    "    # Compute the average sum of squares.\n",
    "    return sum(ds) / len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a5714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y, ypred):\n",
    "    # Compute the absolute value of each term.\n",
    "    ds = [abs(a-b) for (a,b) in zip(y, ypred)]\n",
    "    # Compute the average absolute values.\n",
    "    return sum(ds) / len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9313a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "for d in dataset:\n",
    "    u,i = d['userID'],d['gameID']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    reviewsPerItem[i].append(d)\n",
    "    \n",
    "for u in reviewsPerUser:\n",
    "    reviewsPerUser[u].sort(key=lambda x: x['date'])\n",
    "    \n",
    "for i in reviewsPerItem:\n",
    "    reviewsPerItem[i].sort(key=lambda x: x['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d90c72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat1(d):\n",
    "    # Offset term.\n",
    "    feat = [1]\n",
    "    # hours as a feature.\n",
    "    feat.append(d['hours'])\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e6ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat1(d) for d in dataset]\n",
    "y = [len(d['text']) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b74b4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression model and make predictions\n",
    "mod = linear_model.LinearRegression()\n",
    "mod.fit(X,y)\n",
    "predictions = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01a4668f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007857269704334074"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_0, theta_1 = mod.coef_ # obtaining coefficients\n",
    "theta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570936.2842458936"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_q1 = MSE(y, predictions) # computing MSE\n",
    "mse_q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f32ed5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007857269704334074, 570936.2842458936]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q1'] = [theta_1, mse_q1]\n",
    "answers['Q1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c0b7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q1'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e26bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99a2aba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours = [] # initialize an empty list to store hours across all intersections\n",
    "for d in dataset:\n",
    "    hours.append(d['hours']) # add individual hours of intersection\n",
    "\n",
    "median_hr = statistics.median(hours) # compute median hours of intersection\n",
    "median_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7246aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat2(d):\n",
    "    feat = [1] # offset term\n",
    "    # compute indicator of whether hours played is above global median.\n",
    "    hour_indicator = int(d['hours'] > median_hr)\n",
    "    # Concatenate features together and return the feature vector\n",
    "    return feat + [d['hours']] + [math.log(d['hours'] + 1, 2)] + \\\n",
    "        [math.sqrt(d['hours'])] + [hour_indicator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8786922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat2(d) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1197d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression model and make predictions.\n",
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X,y)\n",
    "predictions = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2402ef0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565419.5340402235"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_q2 = MSE(y, predictions) # compute MSE value\n",
    "mse_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a5d7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = mse_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fad4744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a690f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e524edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat3(d):\n",
    "    # Generate a list of threshold values for easier computation.\n",
    "    thresholds = [1, 5, 10, 100, 1000]\n",
    "    feat = [1] # offset term\n",
    "    # Iterate through the thresholds and append indicator values.\n",
    "    for threshold in thresholds:\n",
    "        feat.append(int(d['hours'] > threshold))\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da7b030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat3(d) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44943983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression model and make predictions.\n",
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X,y)\n",
    "predictions = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4439c4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565405.4395885813"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_q3 = MSE(y, predictions) # compute MSE value\n",
    "mse_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20b470b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = mse_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3846bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69de975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67b6c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat4(d):\n",
    "    feat = [1] # offset term\n",
    "    feat.append(len(d['text'])) # review length as a feature\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "801b7a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat4(d) for d in dataset]\n",
    "y = [d['hours'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d57f7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression model and make predictions.\n",
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X,y)\n",
    "predictions = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c92c3a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75735.70018273004, 90.35613031985152)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = MSE(y, predictions) # compute MSE value\n",
    "mae = MAE(y, predictions) # compute MAE value\n",
    "mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain = \"MAE is better suited for this dataset because it seems we might have large outlier(s) in our dataset, which is punished heavily by the MSE metric. Since the average distance is at a much smaller scale than the average squared distance, MAE would be more suitable for this dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab2a5ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75735.70018273004,\n",
       " 90.35613031985152,\n",
       " 'MAE is better suited for this dataset because it seems we might have large outlier(s) in our dataset, which is punished heavily by the MSE metric. Since the average distance is at a much smaller scale than the average squared distance, MAE would be more suitable for this dataset.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q4'] = [mse, mae, explain]\n",
    "answers['Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44b4eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q4'][:2], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d0ee44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_transform(d):\n",
    "    # compute transformation according to the given formula, with base 2.\n",
    "    return math.log(d['hours'] + 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c841e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trans = [y_transform(d) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8e690b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression model and make predictions.\n",
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X,y_trans)\n",
    "predictions_trans = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fcc3141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.2552542353282785"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_trans = MSE(y_trans, predictions_trans) # MSE using the transformed variable\n",
    "mse_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78d37258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_untransform(predictions):\n",
    "    return (2**predictions - 1) # transform back to variable x with math manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62185cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.43633547, 11.60515115, 11.81893227, 11.79293992, 11.6894965 ,\n",
       "       11.5014136 , 11.52499764, 17.60127735, 11.59053973, 12.96572321])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_untrans = pred_untransform(predictions_trans) # Undoing the transformation\n",
    "predictions_untrans[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b0db71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78668.56502956818"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_untrans = MSE(y, predictions_untrans) # compute MSE value\n",
    "mse_untrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ec7c9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.2552542353282785, 78668.56502956818]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q5'] = [mse_trans, mse_untrans]\n",
    "answers['Q5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55ee62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q5'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e41b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b538f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat6(d):\n",
    "    encode_lst = np.arange(1, 100) # generate list of hours to be compared\n",
    "    one_hot_lst = np.zeros(100, dtype='int32') # one-hot encoding list\n",
    "    hr_played = d['hours'] # extract hours played\n",
    "    if hr_played > 99: # case where hours played is greater than 99\n",
    "        one_hot_lst[-1] = 1\n",
    "    else:\n",
    "        for index in encode_lst: # compare with other number of hours\n",
    "            if hr_played < index:\n",
    "                one_hot_lst[index-1] = 1\n",
    "                break # break out of the loop once one criterion is met\n",
    "    return [1] + list(one_hot_lst) # concatenate offset and one-hot encoding list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b530b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat6(d) for d in dataset]\n",
    "y = [len(d['text']) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3a35fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]\n",
    "ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7f5d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "mses = {}\n",
    "bestC = None\n",
    "bestValidMSE = None\n",
    "\n",
    "for c in [1, 10, 100, 1000, 10000]:\n",
    "    # Fit the linear regression model with training data and make predictions for a given alpha.\n",
    "    mod = linear_model.Ridge(alpha=c)\n",
    "    mod.fit(Xtrain, ytrain)\n",
    "    models[c] = mod\n",
    "    # Generate predictions for validation and test datasets.\n",
    "    y_pred_valid = mod.predict(Xvalid)\n",
    "    y_pred_test = mod.predict(Xtest)\n",
    "    # Compute MSE values accordingly.\n",
    "    mse_valid = MSE(yvalid, y_pred_valid)\n",
    "    mse_test = MSE(ytest, y_pred_test)\n",
    "    # Add MSE value into the dictionary\n",
    "    mses[c] = [mse_valid, mse_test]\n",
    "    # Do comparison to update best value of C and best validation MSE value.\n",
    "    if bestC == None or mse_valid < bestValidMSE:\n",
    "        bestC = c\n",
    "        bestValidMSE = mse_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3eadfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_valid = mses[bestC][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db93b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = mses[bestC][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f49bfb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 581433.8676035535, 560785.7056376459]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q6'] = [bestC, mse_valid, mse_test]\n",
    "answers['Q6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8baaf741",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q6'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0aa5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "504f6f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4724877714627436"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = [d['hours_transformed'] for d in dataset] # extract hours_transformed for each data\n",
    "median = statistics.median(times) # compute the median for hours_transformed\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_indicator(d):\n",
    "    # Indicate True if hours played is less than 1\n",
    "    if d['hours'] < 1:\n",
    "        return 1\n",
    "    # Indicate False otherwise\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "127534da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19913"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notPlayed = [play_indicator(d) for d in dataset] # generate a list of indicators\n",
    "nNotPlayed = sum(notPlayed) # count the intersections with less than 1 hour play time\n",
    "nNotPlayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7d2bed2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.4724877714627436, 19913]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q7'] = [median, nNotPlayed]\n",
    "answers['Q7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1bdbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q7'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67e8ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30b18d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat8(d):\n",
    "    feat = [1] # offset term\n",
    "    feat.append(len(d['text'])) # review length as a feature\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04607068",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat8(d) for d in dataset]\n",
    "y = [d['hours_transformed'] > median for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bad8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression model and make predictions.\n",
    "mod = linear_model.LogisticRegression(class_weight='balanced')\n",
    "mod.fit(X,y)\n",
    "predictions = mod.predict(X) # Binary vector of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44a577ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain evaluation metrics\n",
    "def rates(predictions, y):\n",
    "    TP = sum([(p and l) for (p,l) in zip(predictions, y)])\n",
    "    FP = sum([(p and not l) for (p,l) in zip(predictions, y)])\n",
    "    TN = sum([(not p and not l) for (p,l) in zip(predictions, y)])\n",
    "    FN = sum([(not p and l) for (p,l) in zip(predictions, y)])\n",
    "    \n",
    "    return TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b96e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, TN, FP, FN = rates(predictions, y) # compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR = TP / (TP + FN)\n",
    "TNR = TN / (TN + FP)\n",
    "\n",
    "BER = 1 - 1/2 * (TPR + TNR) # Calculate BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f3004dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24656, 67811, 20007, 62526, 0.4725063905614679]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q8'] = [TP, TN, FP, FN, BER]\n",
    "answers['Q8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3623ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q8'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f0ba96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f10c0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = mod.decision_function(X) # calculate probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.477131385394314, True),\n",
       " (1.477131385394314, True),\n",
       " (1.477131385394314, True),\n",
       " (1.477131385394314, True),\n",
       " (1.477131385394314, True),\n",
       " (1.477131385394314, True),\n",
       " (1.477131385394314, False),\n",
       " (1.477131385394314, False),\n",
       " (1.477131385394314, False),\n",
       " (1.477131385394314, False)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorelabels = list(zip(scores, y))\n",
    "scorelabels.sort(reverse=True)\n",
    "scorelabels[:10] # generate a sorted list of score and label pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedlabels = [x[1] for x in scorelabels] # generate a list of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "177fa669",
   "metadata": {},
   "outputs": [],
   "source": [
    "precs = []\n",
    "recs = []\n",
    "\n",
    "for i in [5, 10, 100, 1000]:\n",
    "    score_k = scorelabels[i][0] # obtain the probability score@k\n",
    "    while scorelabels[i][0] == score_k:\n",
    "            i+=1 # increment k until tie is broken\n",
    "    precs.append(sum(sortedlabels[:i]) / i) # compute precision@k after tie breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a856ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5454545454545454,\n",
       " 0.5454545454545454,\n",
       " 0.6633663366336634,\n",
       " 0.6853146853146853]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q9'] = precs\n",
    "answers['Q9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6d85ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q9'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "26a3af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "435b494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trans = [d['hours_transformed'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e5c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression model and make predictions.\n",
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X,y_trans)\n",
    "predictions_trans = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the interval of which predictions_trans take values.\n",
    "min, max = int(np.min(predictions_trans)), int(np.max(predictions_trans))\n",
    "min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4725063905614679"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q8_BER = answers['Q8'][4]\n",
    "q8_BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f466026",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_thresh = min # Using a fixed threshold to make predictions\n",
    "bestBER = None\n",
    "\n",
    "# y contains True/False labels if the transformed hours is greater than median.\n",
    "\n",
    "# for i in np.arange(np.min(predictions_trans), np.max(predictions_trans), 0.05):\n",
    "for i in np.arange(min, max, 0.05):\n",
    "    # Compute labels with the given threshold\n",
    "    label_pred = [x > i for x in predictions_trans]\n",
    "    \n",
    "    # Compute BER values according to the given threshold\n",
    "    TP, TN, FP, FN = rates(label_pred, y)\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "\n",
    "    BER = 1 - 1/2 * (TPR + TNR)\n",
    "    \n",
    "    # Compare with q8 BER value, update variables accordingly.\n",
    "    if BER < q8_BER:\n",
    "        bestBER = BER\n",
    "        predictions_thresh = i\n",
    "        break # break out as soon as we find a better BER value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4715451499796567, 3.6999999999999975)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestBER, predictions_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7846fa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.6999999999999975, 0.4715451499796567]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q10'] = [predictions_thresh, bestBER]\n",
    "answers['Q10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9c718e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q10'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0795d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3b66ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = dataset[:int(len(dataset)*0.9)]\n",
    "dataTest = dataset[int(len(dataset)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fb03b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "userMedian = defaultdict(list)\n",
    "itemMedian = defaultdict(list)\n",
    "\n",
    "# Compute medians on training data\n",
    "for d in dataTrain:\n",
    "    # Add user into the userMedian if not yet \n",
    "    if d['userID'] not in userMedian:\n",
    "        userMedian[d['userID']] = [d['hours']]\n",
    "    # Append user play hours if user is already in the dictionary\n",
    "    else:\n",
    "        userMedian[d['userID']] += [d['hours']]\n",
    "    # Add item into the itemMedian if not yet \n",
    "    if d['gameID'] not in itemMedian:\n",
    "        itemMedian[d['gameID']] = [d['hours']]\n",
    "    # Append item play hours if user is already in the dictionary\n",
    "    else:\n",
    "        itemMedian[d['gameID']] += [d['hours']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "userMedian = {d: statistics.median(userMedian[d]) for d in userMedian} # compute median play hours for each user\n",
    "itemMedian = {d: statistics.median(itemMedian[d]) for d in itemMedian} # compute median play hours for each game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "416c32c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 3.9]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q11'] = [itemMedian['g35322304'], userMedian['u55351001']]\n",
    "answers['Q11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "841df3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q11'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "19378bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "db5612a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f12(u,i):\n",
    "    # Function returns a single value (0 or 1), global median stored in median_hr\n",
    "    # Case where item is present and its median play hours is greater than global median\n",
    "    if i in itemMedian and itemMedian[i] > median_hr:\n",
    "        return 1\n",
    "    # Case where item is not present but user's median play hours is greater than global median\n",
    "    if i not in itemMedian and userMedian[u] > median_hr:\n",
    "        return 1\n",
    "    # 0 otherwise\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "91c6f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [f12(d['userID'], d['gameID']) for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4b2a0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1 if d['hours'] > median_hr else 0 for d in dataTest] # label by comparing to global median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d98b7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum([a==b for a,b in zip(preds,y)]) / len(y) # compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc9a4ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7410857142857142"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q12'] = accuracy\n",
    "answers['Q12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4f139511",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4b356b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "483a29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set) # Maps an item to the users who rated it\n",
    "itemsPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
    "itemNames = {}\n",
    "\n",
    "for d in dataset:\n",
    "    user,item = d['userID'], d['gameID']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "225d6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    # Size of common items for both s1 and s2\n",
    "    numer = len(s1.intersection(s2))\n",
    "    # Size of all items in either s1 or s2\n",
    "    denom = len(s1.union(s2))\n",
    "    # Edge case\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2b0799c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(i, func, N):\n",
    "    # Initialize a list to store similarities.\n",
    "    similarities = []\n",
    "    # Get users for the given item.\n",
    "    users = usersPerItem[i]\n",
    "    # Iterate through items.\n",
    "    for i2 in usersPerItem:\n",
    "        # Discard item that is the same as the input item.\n",
    "        if i2 == i: continue\n",
    "        # Compute similarity with the input function.\n",
    "        sim = func(users, usersPerItem[i2])\n",
    "        # Append similarity to the similarity list.\n",
    "        similarities.append((sim,i2))\n",
    "    # Sort similarities.\n",
    "    similarities.sort(reverse=True)\n",
    "    # Return N most similar items.\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5a644542",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = mostSimilar(dataset[0]['gameID'], Jaccard, 10) # obtain 10 most similar games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d2202e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07988165680473373, 0.04390243902439024]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q13'] = [ms[0][0], ms[-1][0]]\n",
    "answers['Q13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "df55cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q13'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a266cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b15f52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar14(i, func, N):\n",
    "    # Initialize a list to store similarities\n",
    "    similarities = []\n",
    "    # Obtain a list of users for the item.\n",
    "    users = usersPerItem[i]\n",
    "    # Iterate through list of items.\n",
    "    for i2 in usersPerItem:\n",
    "        # Discard item that is the same as the input item.\n",
    "        if i2 == i: continue\n",
    "        # Compute similarity between two items with the input function.\n",
    "        sim = func(i, i2)\n",
    "        # Append similarity to the list.\n",
    "        similarities.append((sim,i2))\n",
    "    # Sort similarities.\n",
    "    similarities.sort(reverse=True)\n",
    "    # Return N most similar items.\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5325d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingDict = {}\n",
    "\n",
    "for d in dataset:\n",
    "    u,i = d['userID'], d['gameID']\n",
    "    lab = 1 if d['hours'] > median_hr else -1 # Set the label based on a rule\n",
    "    ratingDict[(u,i)] = lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bdc9cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine(i1, i2):\n",
    "    # Between two items\n",
    "    inter = usersPerItem[i1].intersection(usersPerItem[i2])\n",
    "    numer = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    # Computing cosine similarity metrics\n",
    "    for u in inter:\n",
    "        numer += ratingDict[(u,i1)]*ratingDict[(u,i2)]\n",
    "    for u in usersPerItem[i1]:\n",
    "        denom1 += ratingDict[(u,i1)]**2\n",
    "    for u in usersPerItem[i2]:\n",
    "        denom2 += ratingDict[(u,i2)]**2\n",
    "    denom = math.sqrt(denom1) * math.sqrt(denom2)\n",
    "    if denom == 0: return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "55c82dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = mostSimilar14(dataset[0]['gameID'], Cosine, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5fed0ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10251693271055495, 0.061667331307041336]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q14'] = [ms[0][0], ms[-1][0]]\n",
    "answers['Q14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8308daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q14'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "61c3358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "63a5a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingDict = {}\n",
    "\n",
    "for d in dataset:\n",
    "    u,i = d['userID'], d['gameID']\n",
    "    lab = d['hours_transformed'] # Set the label based on a rule\n",
    "    ratingDict[(u,i)] = lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "95406dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = mostSimilar14(dataset[0]['gameID'], Cosine, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ae95f22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3301567230633556, 0.12290154232706603]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q15'] = [ms[0][0], ms[-1][0]]\n",
    "answers['Q15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eac38017",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q15'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "436d2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_midterm.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53acc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
